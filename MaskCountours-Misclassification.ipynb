{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaskContours-Misclassification\n",
    "\n",
    "MaskContours-Testing discovered a few remaining issues, one of which looks like a systematic misclassification of digits where digit N is misclassified as digit N - 1. The working theory is that the atlas template match is *just* to the left of the intended digit's column. If this is the case, should be an easy fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dir = r'E:\\Ultimate\\day1_streams\\masks'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = 'E:/Ultimate/stream_data/masks/102_58.1.png'\n",
    "image_mask_dir = 'E:/Ultimate/stream_data/masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_plot_image(test_image_path):\n",
    "    img_rgb = cv2.cvtColor(cv2.imread(test_image_path), cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    img_inrange = cv2.inRange(img, (0, 0, 0), (180, 255, 80))\n",
    "    img_inverted = cv2.bitwise_not(img_inrange)\n",
    "    \n",
    "    _, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(img_rgb)\n",
    "    ax[1].imshow(img_inverted)\n",
    "    \n",
    "    return img_inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Measure perf\n",
    "#img_inverted = test_and_plot_image(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_blobs(binary_image):\n",
    "    connectivity = 4\n",
    "    output = cv2.connectedComponentsWithStats(binary_image, connectivity, cv2.CV_8S)\n",
    "    \n",
    "    num_labels = output[0]\n",
    "    labels = output[1]\n",
    "    stats = output[2]\n",
    "    centroids = output[3]\n",
    "    \n",
    "    blobs = []\n",
    "    xcoords = []\n",
    "    for label in range(num_labels):\n",
    "        stats_indices = [cv2.CC_STAT_LEFT, cv2.CC_STAT_WIDTH, cv2.CC_STAT_TOP, cv2.CC_STAT_HEIGHT]\n",
    "        xmin, width, ymin, height = [stats[label][i] for i in stats_indices]\n",
    "        \n",
    "        xmax = xmin + width\n",
    "        ymax = ymin + height\n",
    "\n",
    "        blob = np.where(labels[ymin:ymax, xmin:xmax] == label, 255, 0).astype('uint8')\n",
    "        blobs.append(blob)\n",
    "        xcoords.append(xmin)\n",
    "        \n",
    "    return blobs, xcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an atlas from the digits that I have at this directory\n",
    "digits_dir = r'E:/Ultimate/stream_data/digits'\n",
    "digits_index = [[] for _ in range(10)]\n",
    "stats_array = []\n",
    "\n",
    "for d in os.listdir(digits_dir):\n",
    "    full_root = os.path.join(digits_dir, d)\n",
    "    \n",
    "    for f in os.listdir(full_root):\n",
    "        full_path = os.path.join(full_root, f)\n",
    "        \n",
    "        i = int(d)\n",
    "        img = cv2.imread(full_path)\n",
    "        binary_image = cv2.inRange(img, (40, 40, 40), (255, 255, 255))\n",
    "        digits_index[i].append(binary_image)\n",
    "        \n",
    "        stats_array.append(digits_index[i][-1].shape[:2])\n",
    "        \n",
    "for i in range(10):\n",
    "    print(\"{} : {}\".format(i, len(digits_index[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_dim = 32\n",
    "#min_rows = np.min(np.array([len(digits_index[i]) for i in range(10)]))\n",
    "min_rows = 10\n",
    "print(\"Min rows = {}\".format(min_rows))\n",
    "atlas_height = min_rows * cell_dim\n",
    "atlas_width  = cell_dim * 10\n",
    "\n",
    "atlas = np.zeros((atlas_height, atlas_width)).astype('uint8')\n",
    "\n",
    "for digit in range(10):\n",
    "    np.random.shuffle(digits_index[digit])\n",
    "    for i, img in enumerate(digits_index[digit][:min_rows]):\n",
    "        xmin, ymin = digit * cell_dim, i * cell_dim\n",
    "        xmax, ymax = xmin + cell_dim, ymin + cell_dim\n",
    "        \n",
    "        cell_img = cv2.resize(img, (cell_dim, cell_dim))\n",
    "        atlas[ymin:ymax, xmin:xmax] = cell_img\n",
    "        \n",
    "cv2.imwrite(r'C:\\users\\phyto\\desktop\\atlas2.png', atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_directories = [\n",
    "    r'E:/Ultimate/stream_data/corpus_2',\n",
    "    r'E:/Ultimate/stream_data/corpus_3', \n",
    "    r'E:/Ultimate/stream_data/corpus_4', \n",
    "    r'E:/Ultimate/stream_data/corpus_5',\n",
    "    r'E:/Ultimate/stream_data/corpus_6',\n",
    "    r'E:/Ultimate/stream_data/corpus_7'\n",
    "]\n",
    "\n",
    "def get_regions_from_path(img_path):\n",
    "    # We're assuming the GT annotations file is right alongside \n",
    "    # this image.\n",
    "    \n",
    "    regions = []\n",
    "    annotations_path = img_path.replace(\".png\", \".xml\")\n",
    "    if not os.path.exists(annotations_path):\n",
    "        return regions\n",
    "    \n",
    "    with open(annotations_path, 'r') as fr:\n",
    "        tree = ET.parse(fr)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        objects = root.findall('object')\n",
    "        if objects is None or len(objects) == 0:\n",
    "            return regions\n",
    "        else:\n",
    "            img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "            for obj in objects:\n",
    "                cls = obj.find('name').text\n",
    "                if ':' in cls:\n",
    "                    continue\n",
    "                \n",
    "                xmlbox = obj.find('bndbox')\n",
    "                \n",
    "                xmin, xmax = int(xmlbox.find('xmin').text), int(xmlbox.find('xmax').text)\n",
    "                ymin, ymax = int(xmlbox.find('ymin').text), int(xmlbox.find('ymax').text)\n",
    "                \n",
    "                regions.append((img_rgb[ymin:ymax, xmin:xmax], cls))\n",
    "                \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "gtvalues = []\n",
    "for gt_dir in gt_directories:\n",
    "    print(gt_dir)\n",
    "    for filename in [f for f in os.listdir(gt_dir) if f[-4:].lower() == \".png\"]:\n",
    "        full_path = os.path.join(gt_dir, filename)\n",
    "        \n",
    "        regions = get_regions_from_path(full_path)\n",
    "        images.extend([r[0] for r in regions])\n",
    "        gtvalues.extend([r[1] for r in regions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "digits_path = r'E:/Ultimate/stream_data/digits'\n",
    "#nondigits_path = r'C:\\Users\\phyto\\Desktop\\ultimate\\nondigits'\n",
    "\n",
    "def get_image_stats(path):\n",
    "    all_stats = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if f[-4:] == \".png\":\n",
    "                full_path = os.path.join(root, f)\n",
    "                im = cv2.cvtColor(cv2.imread(full_path), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                stats = (im.shape[1], im.shape[0], cv2.countNonZero(im), os.path.basename(root))\n",
    "\n",
    "                all_stats.append(stats)\n",
    "                \n",
    "    return all_stats\n",
    "\n",
    "digits_stats = get_image_stats(digits_path)\n",
    "#nondigits_stats = get_image_stats(nondigits_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_area(im):\n",
    "    return im.shape[0] * im.shape[1]\n",
    "\n",
    "def filter_results(blobs_to_filter):\n",
    "    blobs_by_area = sorted(blobs_to_filter, key = lambda x: img_area(x[0]), reverse=True)\n",
    "    largest = blobs_by_area[0]\n",
    "    \n",
    "    #print([(blob[0].shape[0] / largest[0].shape[0]) for blob in blobs_by_area])\n",
    "    \n",
    "    large_blobs = [('big', blob) for blob in blobs_by_area if (blob[0].shape[0] / largest[0].shape[0]) > 0.87]\n",
    "    large_blobs.extend([('small', blob) for blob in blobs_by_area if (blob[0].shape[0] / largest[0].shape[0]) <= 0.445 and (blob[0].shape[0] / largest[0].shape[0]) >= 0.355])\n",
    "    \n",
    "    return sorted(large_blobs, key = lambda x: x[1][2]), [(blob[0].shape[0] / largest[0].shape[0]) for blob in blobs_by_area]\n",
    "\n",
    "def position_digits(blobs, gtvalue):\n",
    "    blob_positions = [-1] * 4\n",
    "    \n",
    "    big_blobs = [blob[1] for blob in blobs if blob[0] == 'big']\n",
    "    if len(big_blobs) == 0:\n",
    "        return blob_positions\n",
    "    elif len(big_blobs) > 3:\n",
    "        big_blobs = big_blobs[-3:]\n",
    "    \n",
    "    small_blobs = [blob[1] for blob in blobs if blob[0] == 'small']\n",
    "    if len(small_blobs) > 0:\n",
    "        blob_positions[3] = small_blobs[0][1]\n",
    "        \n",
    "    for i, b in enumerate(reversed(big_blobs)):\n",
    "        target_index = 2 - i\n",
    "        blob_positions[target_index] = b[1]\n",
    "\n",
    "    gt_positions = [-1] * 4\n",
    "    for i, d in enumerate(reversed(gtvalue.replace('.', ''))):\n",
    "        index = 3 - i\n",
    "        gt_positions[index] = int(d)\n",
    "            \n",
    "    return blob_positions, gt_positions\n",
    "\n",
    "def confusion_results(blob_positions, gt_positions, confusion_matrix = None):\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = np.zeros((10, 10))\n",
    "        \n",
    "    for i in range(len(gt_positions)):\n",
    "        c_i, c_j = gt_positions[i], blob_positions[i]\n",
    "        \n",
    "        if c_i >= 0 and c_j >= 0:\n",
    "            confusion_matrix[c_j, c_i] += 1\n",
    "            \n",
    "    return confusion_matrix\n",
    "\n",
    "def missing_results(blob_positions, gt_positions):\n",
    "    pass\n",
    "\n",
    "def is_bad(blob_positions, gt_positions):\n",
    "    #\n",
    "    # Just check the 'big' digits\n",
    "    #\n",
    "    zipped = zip(blob_positions[:3], gt_positions[:3])\n",
    "    return not all([i == j for (i, j) in zipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "atlas_copy = atlas.copy()\n",
    "\n",
    "def get_blobs(images):\n",
    "    good_regions = []\n",
    "    bad_regions = []\n",
    "    confusion_matrix = np.zeros((10, 10))\n",
    "    for j, image in enumerate(images):\n",
    "        gtvalue = gtvalues[j]\n",
    "        \n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        #img_inrange = cv2.inRange(hsv_image, (0, 0, 0), (180, 255, 80))\n",
    "        img_inrange = cv2.inRange(hsv_image, (0, 0, 0), (180, 255, 120))\n",
    "        img_inverted = cv2.bitwise_not(img_inrange)\n",
    "\n",
    "        blobs, xcoords = extract_blobs(img_inverted)\n",
    "        blobs_to_render = []\n",
    "        rejected_blobs = []\n",
    "        scores = []# [(blob[0].shape[0] / largest[0].shape[0]) for blob in sorted(blobs, key=lambda x : img_area(x))]\n",
    "\n",
    "        for i, blob in enumerate(blobs):\n",
    "            if np.sum(blob) < 3000:\n",
    "                rejected_blobs.append((blob, -1.0))\n",
    "                continue\n",
    "\n",
    "            blob_cell = cv2.resize(blob, (cell_dim, cell_dim))\n",
    "            response = cv2.matchTemplate(blob_cell, atlas, cv2.TM_CCORR_NORMED)\n",
    "            _, max_val, _, max_loc = cv2.minMaxLoc(response)\n",
    "\n",
    "            if max_val > 0.92:\n",
    "                digit = int(max_loc[0] + cell_dim / 2) // cell_dim\n",
    "\n",
    "                #if digit == 0:\n",
    "                #    cv2.circle(atlas_copy, max_loc + cell_dim / 2, 5, (0, 255, 0))\n",
    "                #if digit == 1:\n",
    "                #    cv2.circle(atlas_copy, max_loc, 5, (255, 0, 0))\n",
    "                blobs_to_render.append((blob, digit, xcoords[i], max_val))\n",
    "            else:\n",
    "                rejected_blobs.append((blob, max_val))\n",
    "\n",
    "\n",
    "        if len(blobs_to_render) == 0:\n",
    "            bad_regions.append((image, blobs_to_render, None, None, gtvalue, rejected_blobs))\n",
    "            continue\n",
    "        \n",
    "        blobs_to_render, _ = filter_results(blobs_to_render)\n",
    "        bs, gs = position_digits(blobs_to_render, gtvalue)\n",
    "        confusion_matrix = confusion_results(bs, gs, confusion_matrix)\n",
    "\n",
    "        if is_bad(bs, gs):\n",
    "            bad_regions.append((image, blobs_to_render, gs, bs, gtvalue, rejected_blobs, scores))\n",
    "        else:\n",
    "            good_regions.append((image, blobs_to_render, gs, bs, gtvalue, rejected_blobs, scores))\n",
    "            \n",
    "    return good_regions, bad_regions, confusion_matrix\n",
    "    \n",
    "def render_regions(regiondata):\n",
    "    for r in regiondata:\n",
    "        #score = compute_gt_score(blobs_to_render, )\n",
    "        blobs_to_render = r[1]\n",
    "        image           = r[0]\n",
    "        gtvalue         = r[4]\n",
    "        #rejected_blobs  = r[5]\n",
    "        rejected_blobs  = [] # disable for now\n",
    "        scores          = [] if len(r) < 7 else r[6]\n",
    "\n",
    "        if len(blobs_to_render) < 1:\n",
    "            plt.imshow(image)\n",
    "            continue\n",
    "\n",
    "        print(scores)\n",
    "        _, ax = plt.subplots(1, len(blobs_to_render) + 1, figsize=(20, 10))\n",
    "        ax[0].imshow(image)\n",
    "        ax[0].set_title(\"GT value = {}\".format(gtvalue))\n",
    "\n",
    "        widths = []\n",
    "        heights = []\n",
    "\n",
    "        for i in range(1, len(blobs_to_render) + 1):\n",
    "            digit = blobs_to_render[i - 1][1][1]\n",
    "            blob  = blobs_to_render[i - 1][1][0]\n",
    "            max_val = blobs_to_render[i - 1][1][3]\n",
    "\n",
    "            widths.append(blob.shape[1])\n",
    "            heights.append(blob.shape[0])\n",
    "\n",
    "            ax[i].set_title(\"Classified as: {} ({:2f})\".format(digit, max_val))\n",
    "            ax[i].imshow(blob)\n",
    "        \n",
    "        _, ax = plt.subplots(1, len(rejected_blobs), figsize=(20, 10))\n",
    "        for i, rb in enumerate(rejected_blobs):\n",
    "            blob = rb[0]\n",
    "            score = rb[1]\n",
    "            \n",
    "            ax[i].imshow(blob)\n",
    "            ax[i].set_title(\"Score = {}\".format(score))\n",
    "\n",
    "        plt.show()\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_images = []\n",
    "N = 32\n",
    "for image in images:\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    #quantized = np.floor(gray*(N/255)*(255/N)).astype('uint8')\n",
    "    canny = cv2.Canny(gray, 80, 210) \n",
    "    \n",
    "    #kernel = np.ones((2,2),np.uint8)\n",
    "    #canny = dilation = cv2.dilate(canny,kernel,iterations = 1)\n",
    "    \n",
    "    new_image = image.copy()\n",
    "    new_image[np.where(canny > 0)] = (0, 0, 0)\n",
    "    processed_images.append(new_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good_regions, bad_regions, confusion_matrix = get_blobs(images)\n",
    "good_regions, bad_regions, confusion_matrix = get_blobs(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(atlas_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 519; 41 @ 110\n",
    "# 522; 38 @ 120\n",
    "# 520, 40 @ 125\n",
    "# 518; 42 @ 130\n",
    "# 515; 45 @ 140\n",
    "print(len(good_regions))\n",
    "print(len(bad_regions))\n",
    "print(len(good_regions) / (len(good_regions) + len(bad_regions)))\n",
    "\n",
    "# with and w/o oquantized, + dilation: 523; 37, 0.91 thresh\n",
    "# no quantization, no dilation: 523, 37, 0.91 thresh\n",
    "# no quantization, no dilation: 528, 32, 0.92 thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#render_regions(good_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#render_regions(bad_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dir = r'C:\\Users\\phyto\\Desktop\\temp\\thresholding_experiment'\n",
    "\n",
    "for i, r in enumerate(bad_regions):\n",
    "    image = cv2.cvtColor(r[0], cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    full_path = os.path.join(dump_dir, str(i) + '.png')\n",
    "    # disable for now\n",
    "    cv2.imwrite(full_path, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
